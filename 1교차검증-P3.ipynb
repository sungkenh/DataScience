{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차 검증\n",
    "\n",
    "이번 예에서는 k-폴드 교차검증을 수행하기 위해서 파이선이 제공하는 [scikit-learn](http://scikit-learn.org/stable/index.html)을 사용하는 방법을 소개하겠다.\n",
    "\n",
    "---\n",
    "데이터 분석에서는 많은 경우에 데이터로부터 어떤 통계적인 모델을 만드는 작업을 하게 된다. 예를 들면 선형 예측의 경우 새로운 데이터가 들어오면 이를 기술하는 [선형예측모델](https://en.wikipedia.org/wiki/Line_fitting)을 만들고 이것을 이용하여 새로운 입력 데이터로부터 예측 값을 추정하는데 사용한다. 이러한 모델을 만들기 위해서는 데이터로부터 모델을 만드는 작업을 먼저 해야 하는데, 예를 들어 새로운 이미지를 보고 이 이미지가 무엇을 나타내는지를 예측하는데 모델을 만들어야 한다. 또한 어떤 사건들이 자주 동시에 같이 발생한다고 하면 [연관규칙](https://en.wikipedia.org/wiki/Association_rule_learning)을 만들어 두고 어떤 사건이 발생하면 이와 동시에 다른 사건이 같이 발생할 확률을 예측하기도 한다. 어떤 물건을 사는 사람은 특정한 다른 물건을 같이 살 확률이 얼마일 것이라는 것을 맞추는 모델도 대표적인 예이다. 이러한 분석을 장바구니 분석 (market basket model)이라고도 한다.\n",
    "\n",
    "이와 같이 주어진 데이터로부터 만든 모델이 실제로 얼마나 잘 동작하는지를 확인하려면 테스트 데이터를 이용하여 성능을 검증하여야 한다. 모델을 만드는데 사용하는 데이터를 훈련(train) 데이터라고 하고 이 모델을 테스트하는데 사용하는 데이터를 테스트(test)데이터라고 부른다.\n",
    "\n",
    "만들어진 데이터 분석 (또는 예측) 모델이 테스트 데이터에 대해서 잘 동작하면 모델을 잘 만든 것이지만, 테스트 데이터에 대해서 잘 동작하지 않으면 훈련데이터에 대해서만 잘 동작하게 만들어진, 즉, 불완전한 모델을 만든셈이고 이러한 현상을 [과적합](https://en.wikipedia.org/wiki/Overfitting)) 이라고 부른다. 여기서 과적합이라는 말의 의미는 훈련용 데이터에 대해서만 과하게 잘 동작하지 실제 상황의 일반적인 데이터, 즉 훈련용으로 사용되지 않은 데이터에 대해서는 잘 동작하지 않는다는 것을 의미한다. \n",
    "\n",
    "좋은 데이터 분석 모델은 과적합이 발생하면 안된다. 즉, 훈련용 데이터에 대해서만 잘 동작하지 않고, 임의의 데이터에 대해서도 범용적으로 잘 동작하는 모델을 만들어야만 한다.\n",
    "\n",
    "과적합 현상을 피하려면 데이터 분석에 사용할 데이터를 두 개의 그룹 즉, 훈련용 데이터와 테스트용 데이터로 미리 잘 나누는 것이 필요하다.\n",
    "\n",
    "모델이 얼마나 잘 동작하는지는 테스트 데이터, 즉 모델을 만드는데 사용하지 않은 데이터에 대해서 모델이 안정적으로 잘 동작하는 지를 확인해야 한다.\n",
    "\n",
    "데이터 분석 작업에서는 모델을 한번에 바로 만드는 것이 아니라 여러번의 시행착오를 거쳐서 가장 적합한 모델을 만들게 된다. 즉, 분석 작업은 모델을 설계하고 검증하는 작업을 반복 시행해야 한다. 모델을 구성하는 알고리즘의 선택, 분석 작업을 할 때 사용되는 파라미터의 변경(예를 들어 신경만에서 뉴런의 갯수 조정 또는 의사결정나무 알고리즘에서 트리의 갯수 조정 등)이 필요하다.\n",
    "\n",
    "주어진 데이터를 최대한 적절하게 훈련용 데이터와 테스트 데이터로 나누는 방법으로, k-폴드 교차 검증 (cross validation) 방법이 널리 사용된다. 여기서는 훈련용 데이터로 한가지 세트만 사용하는 것이 아니라, 데이터를 서로 바꾸어 가면서 훈련을 교대로 하게 된다.\n",
    "\n",
    "예를 들어 주어진 훈련용 데이터를 동일한 크기로 4 부분으로 나눈다. 첫 부분을 검증용(validation) 데이터로 사용하고, 나머지 세 부분을 훈련용 데이터로 사용하여 모델을 만들고 모델의 오차를 계산해본다. 다음에는 두번째 부분을 검증용 데이터로 사용하고, 나머지 세 부분을 훈련용 데이터로 사용하여 모델을 만들고 모델의 오차를 계산해본다. 이와 같은 작업을 네번 반복할 수 있으며 네번 모두 훈련에 사용하지 않은 데이터를 검증용으로 각각 사용함으로써 객관적인 검증을 네번 반복할 수 있게 된다. 이러한 방법을 k-폴드 교차검증이라고 하며 널리 사용되는 방법이다 (여기서 k=4임).\n",
    "\n",
    "교차검증을 수행하는데는 많은 컴퓨팅 시간이 필요하지만 그만큼 과적합 오류를 범할 확률을 줄이게 된다. 만일 주어진 데이터가 매우 클 때에는 \n",
    "[규정화](https://en.wikipedia.org/wiki/Regularization_(mathematics)) 방법 등을 사용해야 한다. 이외에도 교차 검증과 유사한 방법은 다양하게 소개되어 있다. \n",
    "\n",
    "교차검즈에서 적절한 k의 값은 얼마일까? k=2로하면 주어진 훈련 데이터를 두 세트로 나누어서 하나는 훈련용으로 다른 하나는 검증용으로 사용하며, 다음에는 이들의 역할을 바꾸는 것을 것을 말한다. 경우에 따라서는 k=10으로 하여 검증을 여러번 나누어 하는 것도 가능하다. 적적한 k값의 선택은 분석 데이터의 성격에 따라 다르게 정해진다. 보통 k는 3~5 정도만 해도 충분하다.\n",
    "\n",
    "이번 예에서는 주어진 훈련용 데이터를 다시 훈련용 및 검증용으로 적절히 나누는 것을 설명하겠다. MNIST 데이터는 이미 훈련용 데이터와 테스트용 데이터로 나누어져 있는데, 여기서는 훈련용 데이터를 다시 훈련용과 검증용 (validation) 데이터 셋으로 나누어서 교차검증에 사용하는 방법을 소개하겠다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn 설치\n",
    "아직 scikit-learn 라이브러리가 자신의 컴퓨터에 설치되어 있지 않다면 이를 먼저 설치해야하는데, 터미널에서 다음의 명령으로 scikit-learn을 설치할 수 있다.\n",
    "\n",
    "conda install scikit-learn\n",
    "\n",
    "또는 아래의 명령을 사용할 수 있다\n",
    "\n",
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [25000 25001 25002 ..., 49997 49998 49999] TEST: [    0     1     2 ..., 24997 24998 24999]\n",
      "TRAIN: [    0     1     2 ..., 24997 24998 24999] TEST: [25000 25001 25002 ..., 49997 49998 49999]\n"
     ]
    }
   ],
   "source": [
    "from data.load_mnist import load_mnist\n",
    "training_images, training_labels, testing_images, testing_labels = load_mnist()\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# 훈련데이터와 테스트데이터를 랜덤화 한다\n",
    "training_images, training_labels = shuffle(training_images, training_labels)\n",
    "testing_images, testing_labels = shuffle(testing_images, testing_labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 데이터를 다시 나누어 훈련용과 검증용으로 구분한다\n",
    "training_images, validation_images, training_labels, validation_labels = train_test_split(training_images, training_labels, test_size=10000, random_state=42)\n",
    "\n",
    "# k-폴드 교차 검증을 한다\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=2)\n",
    "for train_index, validation_index in kf.split(training_images):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", validation_index)\n",
    "    kfold_training_images, kfold_validation_images = training_images[train_index], training_images[validation_index]\n",
    "    kfold_training_labels, kfold_validation_labels = training_labels[train_index], training_labels[validation_index]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
