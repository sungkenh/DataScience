{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보스턴 하우싱 데이터\n",
    "1978년, 경제학자인 [David Harrison](http://www.nera.com/experts/dr-david-harrison-jr.html)과 [Daniel Rubinfield](https://www.law.berkeley.edu/our-faculty/faculty-profiles/daniel-rubinfeld/)는 다음의 [논문](http://www.colorado.edu/ibs/crs/workshops/R_1-11-2012/root/Harrison_1978.pdf) 에서 보스턴 지역의 공기의 품질과 부동산 가격의 관계를 분석하는 내용을 발표했고 이는 1300회 이상 인용되었다([1300 times](https://scholar.google.co.kr/scholar?um=1&ie=UTF-8&lr&cites=13412889939065541163)) 이 논문에서 사용한 [데이터셋](http://www.census.gov/geo/reference/gtc/gtc_ct.html)은 1970년의 보스턴 센서스[1970 Boston census](https://www2.census.gov/prod2/decennial/documents/39204513p3ch05.pdf) 데이터를 이용한 것인데, 이데이터는 이후 여러가지 데이터 분석 방법들의 성능을 비교하는 목적으로 사용되고 있다.\n",
    "\n",
    "최초의 데이터 셋은 카네기 멜론 대학의 데이터 저장소 [StatLib](http://lib.stat.cmu.edu/datasets/)에서 소개되었다[boston](http://lib.stat.cmu.edu/datasets/boston). 이 데이터는 편의상 \"Boston Housing\" 데이터라고 불린다.\n",
    "\n",
    "각 센서는 506개의 샘플이 있으며 각 샘플은 다음과 같이 14개의 값을 측정하였다:\n",
    "\n",
    "| Name    | Meaning                                                               |\n",
    "|---------|-----------------------------------------------------------------------|\n",
    "| CRIM    | per capita crime rate by town                                         |\n",
    "| ZN      | proportion of residential land zoned for lots over 25,000 sq.ft.      |\n",
    "| INDUS   | proportion of non-retail business acres per town                      |\n",
    "| CHAS    | Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) |\n",
    "| NOX     | nitric oxides concentration (parts per 10 million)                    |\n",
    "| RM      | average number of rooms per dwelling                                  |\n",
    "| AGE     | proportion of owner-occupied units built prior to 1940                |\n",
    "| DIS     | weighted distances to five Boston employment centres                  |\n",
    "| RAD     | index of accessibility to radial highways                             |\n",
    "| TAX     | full-value property-tax rate per \\$10,000                             |\n",
    "| PTRATIO | pupil-teacher ratio by town                                           |\n",
    "| B       | 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town        |\n",
    "| LSTAT   | % lower status of the population                                      |\n",
    "| MEDV    | Median value of owner-occupied homes in \\$1000's                      |\n",
    "\n",
    "그런데 이 데이터에는 문제가 있었는데, 1996년에 경제학자인 [Otis Gilley](http://www.business.latech.edu/gilley/)와 [R. Kelley Pace](https://business.lsu.edu/Finance/Pages/FacultyMember.aspx?UN=kpace)는 다음과 같은 [논문](http://spatial-statistics.com/pace_manuscripts/jeem_ms_dir/pdf/fin_jeem.pdf)을 발표하여 이 데이터와 실제 센서스 데이터를 비교하여 두가지 이슈를 찾아냈다: 먼저 8개의 샘플에서 median household values (MEDV)가 잘 못 기록되었고 16개의 샘플에서 MEDV의 임계치가 5만불 이상으로 설정된 것이 잘 못 적용된 것을 발견했다. \n",
    "\n",
    "그들은 잘못 기록된 데이터를 정정하였고, 그 결과 Harrison과 Rubinfield이 제시한 분석방법의 성능이 조금 향상된 것을 알아냈다. 다음해에 그들은 다른 [논문](http://link.springer.com/article/10.1023/A:1007762613901)을 발표했는데, 여기서 센서스 구역을 나타내는 id, 구역의 경도 및 위도 값, 해당지역 명칭 등을 분석에 도입하였다. 이를 통해서 인접한 지역은 유사한 값을 갖는다는 가정을 사용하여 보다 정확한 예측이 가능한 것을 보였다.\n",
    "\n",
    "위와 같은 수정을 한 새로운 데이터셋을 [boston_corrected](http://lib.stat.cmu.edu/datasets/boston_corrected.txt)\"로 다시 업로드하였다. \n",
    "\n",
    "이 데이터셋에는 506개의 샘플이 있고 아래과 같이 7개의 변수가 추가되었다:\n",
    "\n",
    "| Name  | Meaning                                                                                                    |\n",
    "|-------|-------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| OBS.  | Observation number (the first example is 1, the second example is 2, and so on)                                                                   |\n",
    "| TOWN  | The name of the corresponding town                                                                                                        |\n",
    "| TOWN# | The number of the corresponding town (the first town is 1, the second town is 2, and so on); each town can contain multiple census tracts |\n",
    "| TRACT | The id of the census tract as defined by the 1970 census                                                                                  |\n",
    "| LAT   | The latitude coordinate of the census tract (unclear where within the tract this is)                                                      |\n",
    "| LONG  | The longitude coordinate of the census tract (unclear where within the tract this is)                                                     |\n",
    "| CMEDV | The corrected median value of owner-occupied homes in \\$1000's  (different from MEDV in 8 instances)                                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 데이터 소스\n",
    "정정된 데이터셋은 StatLib에 텍스트 파일형태로 다음과 같이 제공된다\n",
    "\n",
    "- http://lib.stat.cmu.edu/datasets/boston_corrected.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1단계 : 데이터 저장소 확인\n",
    "우선 데이터를 저장할 디렉토리를 확인한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# . 는 현재 디렉토리를 가리킨다\n",
    "# 자주 사용되는 변수명으로, 데이터 저장소를 가리키는 변수를 다음과 같이 정의했다\n",
    "path_to_directory = \"./data\"\n",
    "path_to_data = \"./data/boston_housing\"\n",
    "\n",
    "# os 는 운영체제를 사용하는데 필요한 라이브러리이다\n",
    "# 이를 사용하면 명령문 창에서 사용하는 임의의 명령문을 호출할 수 있다\n",
    "import os  \n",
    "\n",
    "if not os.path.isdir(path_to_directory): # data 디렉토리가 존재하지 않으면 새로 디렉토리를 만든다\n",
    "    os.mkdir(path_to_directory)\n",
    "\n",
    "# shutil를 사용하면 파일과 디렉토리를 쉽게 다룬다\n",
    "# 이미 디렉토리가 존재하면 이를 지룬다. 실제로는 어떤 파일이 존재하는지를 보고 필요한 데이터만 다운로드한다\n",
    "import shutil\n",
    "    \n",
    "if os.path.isdir(path_to_data):\n",
    "    shutil.rmtree(path_to_data) # 디렉토리와 그 내용을 지운다\n",
    "\n",
    "os.mkdir(path_to_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2단계 : 데이터 다운로드\n",
    "다음에는 데이터를 다운로드 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished downloading Boston Housing Data!\n"
     ]
    }
   ],
   "source": [
    "# requests는 URL을 이용하기 위해 사용한다 \n",
    "import requests\n",
    "\n",
    "# 아래에서는 편의상 URL내용을 직접 입력했다\n",
    "# Requests나 BeautifulSoup4 라이브러리를 사용하면 URL 값을 자동으로 추출할 수 있다\n",
    "\n",
    "url = \"http://lib.stat.cmu.edu/datasets/boston_corrected.txt\"\n",
    "name = \"boston_corrected.txt\"\n",
    "path = os.path.join(path_to_data, name)\n",
    "\n",
    "response = requests.get(url) \n",
    "if response.status_code == 200: # HTTP response code 200은 \"OK\"를 나타낸다\n",
    "    \n",
    "    with open(path, 'w') as outfile: # 'w' 을 사용하면 쓰기 (write)를 할 수 있다\n",
    "        outfile.write(response.text)  # HTTP response 출력으로 파일에 쓴다\n",
    "else:\n",
    "    # 응답 코드가 200 \"OK\"가 아니면 오류를 던지면서(thraw) 프로그램을 종료하게 한다\n",
    "    raise ValueError(\"Requests returned a non-200 HTTP status code (status: {}) when downloading {}.\".format(r.status_code, url))\n",
    "\n",
    "print(\"Finished downloading Boston Housing Data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3단계 : 데이터 로드\n",
    "\n",
    "Boston Housing 데이터는 텍스트 형식으로 저장되는데 여러개의 헤더 필드와 실제 데이터를 저장하고 있다. 이 데이터를 프로그램에서 다루기 좋은 형태로 변경하고자 한다. [Pandas](http://pandas.pydata.org/)가 제공하는[dataframe](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)를 사용하면 테이블 형태로 데이터를 편리하게 다룰 수 있다. 이 예제에서는[read_csv](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) 도구를 사용하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pandas는 데이터분석에 널리 사용되는 파이선 라이브러이다\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# skiprows=9 : 9개의 헤더 라인을 스킵함\n",
    "# header=0 : 다음의 라인을 컬럼 이름으로 사용함\n",
    "# delimiter=\"\\t\" : 각 행의 데이터가 탭으로 구분됨을 나타냄\n",
    "\n",
    "data = pd.read_csv(path, skiprows=9, header=0, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4 단계 : 데이터 확인\n",
    "\n",
    "21개의 열과 506개의 행이 남는다. 8개의 샘플에서 MEDV값과 CMEDV의 값이 다르며, MEDV나 CMEDV 값이 50.0을 초과할 수 없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 21개의 컬럼이 있는지를 확인한다\n",
    "\n",
    "columns = data.columns\n",
    "assert(len(columns) == 21)\n",
    "\n",
    "# 21개의 컬럼이 아래의, 우리가 원하는 이름들과 일치하는지 확인한다\n",
    "expected_columns = [\"OBS.\", \"TOWN\", \"TOWN#\", \"TRACT\", \"LON\", \"LAT\", \"MEDV\", \"CMEDV\", \"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"]\n",
    "\n",
    "# 두개의 리스트의 내용이 항목별로 일치하는지 확인하기 위해  == 를 사용한다. \n",
    "# all() 함수는 모든 항목이 각각 일치하는지를 확인한다\n",
    "\n",
    "assert((columns == expected_columns).all())\n",
    "\n",
    "# 506개의 항목(행)이 있는지 확인한다\n",
    "# data에 저장된 샘플의 인덱스 크기를 len()으로 알아내고 이것이 506과 일치하는지 비교한다\n",
    "\n",
    "num_examples = len(data.index.values.tolist()) \n",
    "assert(num_examples == 506)\n",
    "\n",
    "# medv과 cmedv 값이 다른 경우가 8개만 존재하는지 확인한다\n",
    "\n",
    "medv = data['MEDV'].values.tolist()\n",
    "cmedv = data['CMEDV'].values.tolist()\n",
    "different_count = 0\n",
    "\n",
    "for i in range(0, len(medv)):\n",
    "    if medv[i] != cmedv[i]:\n",
    "        different_count += 1\n",
    "assert(different_count == 8)\n",
    "\n",
    "# medv 값이 50.0을 초과하는 경우가 있는지 확인한다\n",
    "\n",
    "above_50 = [value for value in medv if value > 50.0]\n",
    "assert(len(above_50) == 0)\n",
    "\n",
    "# cmedv 값이 50.0을 초과하는 경우가 있는지 확인한다\n",
    "above_50 = [value for value in cmedv if value > 50.0]\n",
    "assert(len(above_50) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지 프로그램이 실행되었으면 이제 데이터를 정상적으로 다운로드하고 내용을 점검한 것이다.\n",
    "\n",
    "###### 5단계 : 코드 재구성\n",
    "\n",
    "지금까지 작성된 코드를 간결하게 정리하여 load_boston_housing.py 하나의 프로그램으로 작정하였다. 다음과 같이 data를 얻을 수 있다.\n",
    "\n",
    "`data = load_boston_housing()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "path_to_directory = \"./data\"\n",
    "path_to_data = os.path.join(path_to_directory, \"boston_housing\")\n",
    "\n",
    "url = \"http://lib.stat.cmu.edu/datasets/boston_corrected.txt\"\n",
    "name = \"boston_corrected.txt\"\n",
    "path = os.path.join(path_to_data, name)\n",
    "\n",
    "def check_destination():\n",
    "    if not os.path.isdir(path_to_directory):\n",
    "        os.mkdir(path_to_directory)\n",
    "    \n",
    "    if not os.path.isdir(path_to_data):\n",
    "        os.mkdir(path_to_data)\n",
    "\n",
    "def download_boston_housing(): \n",
    "    if not os.path.exists(path):\n",
    "        response = requests.get(url) \n",
    "        if response.status_code == 200: # HTTP response code 200은 \"OK\"를 나타낸다\n",
    "            # with open() as f 작업이 종료되면 파일을 닫는다\n",
    "            with open(path, 'w') as outfile: # 'w' 을 사용하면 쓰기 (write)를 할 수 있다\n",
    "                outfile.write(response.text)  # HTTP response 출력으로 파일에 쓴다\n",
    "        else:\n",
    "            # 응답 코드가 200 \"OK\"가 아니면 오류를 던지면서(thraw) 프로그램을 종료하게 한다\n",
    "            raise ValueError(\"Requests returned a non-200 HTTP status code (status: {}) when downloading {}.\".format(r.status_code, url))\n",
    "    \n",
    "def verify_boston_housing():\n",
    "    # 21개의 컬럼이 있는지를 확인한다\n",
    "    \n",
    "    columns = data.columns\n",
    "    assert(len(columns) == 21)\n",
    "\n",
    "    # 21개의 컬럼이 아래의, 우리가 원하는 이름들과 일치하는지 확인한다\n",
    "\n",
    "    expected_columns = [\"OBS.\", \"TOWN\", \"TOWN#\", \"TRACT\", \"LON\", \"LAT\", \"MEDV\", \"CMEDV\", \"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"]\n",
    "    # 두개의 리스트의 내용이 항목별로 일치하는지 확인하기 위해  == 를 사용한다. \n",
    "    # all() 함수는 모든 항목이 각각 일치하는지를 확인한다\n",
    "\n",
    "    assert((columns == expected_columns).all())\n",
    "\n",
    "    # 506개의 항목(행)이 있는지 확인한다\n",
    "    # data에 저장된 샘플의 인덱스 크기를 len()으로 알아내고 이것이 506과 일치하는지 비교한다\n",
    "\n",
    "\n",
    "    num_examples = len(data.index.values.tolist()) \n",
    "    assert(num_examples == 506)\n",
    "\n",
    "    # medv과 cmedv 값이 다른 경우가 8개만 존재하는지 확인한다\n",
    "\n",
    "    medv = data['MEDV'].values.tolist()\n",
    "    cmedv = data['CMEDV'].values.tolist()\n",
    "    different_count = 0\n",
    "    for i in range(0, len(medv)):\n",
    "        if medv[i] != cmedv[i]:\n",
    "            different_count += 1\n",
    "    assert(different_count == 8)\n",
    "\n",
    "    # medv 값이 50.0을 초과하는 경우가 있는지 확인한다\n",
    "\n",
    "    above_50 = [value for value in medv if value > 50.0]\n",
    "    assert(len(above_50) == 0)\n",
    "\n",
    "    # cmedv 값이 50.0을 초과하는 경우가 있는지 확인한다\n",
    "\n",
    "    above_50 = [value for value in cmedv if value > 50.0]\n",
    "    assert(len(above_50) == 0)\n",
    "            \n",
    "def load_boston_housing():\n",
    "    check_destination()\n",
    "    download_boston_housing()\n",
    "    data = pd.read_csv(path, skiprows=9, header=0, delimiter=\"\\t\")  \n",
    "    verify_boston_housing()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "}{}{}"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
